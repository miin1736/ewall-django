"""
Product sync and data pipeline tasks
ë„¤ì´ë²„ ì‡¼í•‘ API ê¸°ë°˜ ìë™í™” ì‹œìŠ¤í…œ
"""
from celery import shared_task
from django.utils import timezone
from django.db import transaction
import logging

logger = logging.getLogger(__name__)


@shared_task(bind=True, max_retries=3)
def sync_naver_outlet_products(self):
    """ë„¤ì´ë²„ ì‡¼í•‘ ì´ì›”ìƒí’ˆ ìë™ ë™ê¸°í™”
    
    ì‹¤í–‰ ì£¼ê¸°: 6ì‹œê°„ë§ˆë‹¤ (Celery Beat)
    
    Steps:
        1. ë„¤ì´ë²„ ì‡¼í•‘ APIë¡œ ì´ì›”ìƒí’ˆ ê²€ìƒ‰
        2. ë¸Œëœë“œë³„ ë°ì´í„° ìˆ˜ì§‘
        3. ë°ì´í„° ì •ê·œí™” ë° ê²€ì¦
        4. GenericProductì— upsert
        5. í’ˆì ˆ ìƒí’ˆ ì²˜ë¦¬
    """
    try:
        from scripts.advanced_naver_outlet_loader import (
            NaverShoppingCrawler,
            BRAND_SEARCH_KEYWORDS
        )
        from apps.products.models import GenericProduct
        from apps.core.models import Brand, Category
        from django.utils.text import slugify
        
        logger.info("ğŸš€ Starting Naver Shopping outlet products sync")
        
        crawler = NaverShoppingCrawler()
        
        total_searched = 0
        total_created = 0
        total_updated = 0
        total_errors = 0
        
        # ê¸°íƒ€ ì¹´í…Œê³ ë¦¬ ê°€ì ¸ì˜¤ê¸°
        try:
            generic_category = Category.objects.get(slug='generic')
        except Category.DoesNotExist:
            generic_category, _ = Category.objects.get_or_create(
                slug='generic',
                defaults={'name': 'ê¸°íƒ€', 'category_type': 'clothing'}
            )
        
        # ê° ë¸Œëœë“œë³„ ì´ì›”ìƒí’ˆ ê²€ìƒ‰
        for brand_kr, keywords in BRAND_SEARCH_KEYWORDS.items():
            for keyword in keywords:
                try:
                    query = f"{brand_kr} {keyword}"
                    logger.info(f"ğŸ” Searching: {query}")
                    
                    # ë„¤ì´ë²„ ì‡¼í•‘ API ê²€ìƒ‰
                    products = crawler.search_products(query, display=100)
                    total_searched += len(products)
                    
                    # ê° ìƒí’ˆ ì²˜ë¦¬
                    for raw_product in products:
                        try:
                            # ë°ì´í„° ì •ê·œí™”
                            normalized = crawler.normalize_product(raw_product)
                            
                            # ë°ì´í„° ê²€ì¦
                            if not crawler.validate_product(normalized):
                                continue
                            
                            # ë¸Œëœë“œ ë§¤í•‘
                            brand_name_kr = normalized.get('brand', brand_kr)
                            brand_slug = crawler.get_brand_slug(brand_name_kr)
                            
                            # ë¸Œëœë“œ ì¡°íšŒ/ìƒì„±
                            brand, _ = Brand.objects.get_or_create(
                                slug=brand_slug,
                                defaults={
                                    'name': brand_name_kr,
                                    'logo_url': '',
                                    'description': ''
                                }
                            )
                            
                            # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
                            category_name = normalized.get('category', 'ê¸°íƒ€')
                            category = crawler.get_or_create_category(category_name)
                            if not category:
                                category = generic_category
                            
                            # ê³ ìœ  slug ìƒì„± (ì œëª© + product_id)
                            product_id = normalized['product_id']
                            title = normalized['title']
                            title_slug = slugify(title[:50])
                            unique_slug = f"{title_slug}-{product_id}"
                            
                            # DB ë°ì´í„° ì¤€ë¹„
                            db_data = {
                                'brand': brand,
                                'category': category,
                                'title': title[:500],
                                'slug': unique_slug[:200],
                                'image_url': normalized.get('image_url', ''),
                                'price': normalized['price'],
                                'original_price': normalized.get('original_price', normalized['price']),
                                'discount_rate': normalized.get('discount_rate', 0),
                                'seller': normalized.get('seller', '')[:100],
                                'deeplink': normalized.get('deeplink', ''),
                                'in_stock': True,
                                'score': 0,
                                'source': 'naver_shopping',
                                'updated_at': timezone.now(),
                            }
                            
                            # Upsert
                            product, is_created = GenericProduct.objects.update_or_create(
                                id=product_id,
                                defaults=db_data
                            )
                            
                            if is_created:
                                total_created += 1
                                logger.debug(f"âœ… Created: {title[:50]}")
                                
                                # ìƒˆ ìƒí’ˆ: ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± (ë°±ê·¸ë¼ìš´ë“œ)
                                try:
                                    generate_image_embedding.delay(
                                        product_id=str(product.id),
                                        image_url=product.image_url
                                    )
                                except Exception as emb_error:
                                    logger.warning(f"âš ï¸ Failed to queue embedding for {product_id}: {emb_error}")
                            else:
                                total_updated += 1
                                logger.debug(f"ğŸ”„ Updated: {title[:50]}")
                                
                        except Exception as e:
                            logger.error(f"âŒ Failed to process product: {e}")
                            total_errors += 1
                            continue
                    
                except Exception as e:
                    logger.error(f"âŒ Search failed for '{query}': {e}")
                    continue
        
        # ì˜¤ë˜ëœ ìƒí’ˆ í’ˆì ˆ ì²˜ë¦¬ (7ì¼ ì´ìƒ ì—…ë°ì´íŠ¸ ì•ˆ ëœ ìƒí’ˆ)
        from datetime import timedelta
        cutoff_date = timezone.now() - timedelta(days=7)
        outdated_count = GenericProduct.objects.filter(
            source='naver_shopping',
            updated_at__lt=cutoff_date,
            in_stock=True
        ).update(in_stock=False)
        
        result = {
            'searched': total_searched,
            'created': total_created,
            'updated': total_updated,
            'errors': total_errors,
            'outdated_marked': outdated_count,
            'timestamp': timezone.now().isoformat()
        }
        
        logger.info(
            f"âœ… Naver Shopping sync complete: "
            f"searched={total_searched}, created={total_created}, "
            f"updated={total_updated}, errors={total_errors}, "
            f"outdated={outdated_count}"
        )
        
        return result
        
    except Exception as exc:
        logger.error(f"âŒ Naver Shopping sync failed: {exc}")
        raise self.retry(exc=exc, countdown=600)  # 10ë¶„ í›„ ì¬ì‹œë„


@shared_task(bind=True)
def snapshot_prices(self):
    """ëª¨ë“  GenericProductì˜ í˜„ì¬ ê°€ê²©ì„ PriceHistoryì— ìŠ¤ëƒ…ìƒ· ì €ì¥
    
    ì‹¤í–‰ ì£¼ê¸°: ë§¤ì¼ ìì • (Celery Beat)
    
    Steps:
        1. GenericProductì—ì„œ in_stock=True ìƒí’ˆ ì¡°íšŒ
        2. ê° ìƒí’ˆì˜ í˜„ì¬ price, original_price, discount_rate ì €ì¥
        3. ì¤‘ë³µ ë°©ì§€: ì˜¤ëŠ˜ ì´ë¯¸ ê¸°ë¡ëœ ìƒí’ˆì€ ìŠ¤í‚µ
        4. ê°€ê²© í•˜ë½ ê°ì§€ ë° Alert íŠ¸ë¦¬ê±°
    """
    try:
        from apps.products.models import GenericProduct, PriceHistory
        
        logger.info("ğŸ“¸ Starting daily price snapshot")
        
        # ì¬ê³  ìˆëŠ” ìƒí’ˆë§Œ
        products = GenericProduct.objects.filter(in_stock=True)
        logger.info(f"Processing {products.count()} GenericProduct products")
        
        total_snapshots = 0
        skipped = 0
        errors = 0
        
        # ì˜¤ëŠ˜ ë‚ ì§œ (ìì • ê¸°ì¤€)
        today = timezone.now().date()
        
        for product in products:
            try:
                # ì˜¤ëŠ˜ ì´ë¯¸ ê¸°ë¡í–ˆëŠ”ì§€ í™•ì¸
                existing = PriceHistory.objects.filter(
                    product_id=product.id,
                    recorded_at__date=today
                ).exists()
                
                if existing:
                    skipped += 1
                    continue
                
                # ê°€ê²© ìŠ¤ëƒ…ìƒ· ìƒì„±
                PriceHistory.objects.create(
                    product_id=product.id,
                    product_type='GenericProduct',
                    price=product.price,
                    original_price=product.original_price,
                    discount_rate=product.discount_rate
                )
                total_snapshots += 1
                
            except Exception as e:
                logger.error(f"Failed to snapshot {product.id}: {e}")
                errors += 1
                continue
        
        logger.info(
            f"âœ… Price snapshot complete: "
            f"created={total_snapshots}, skipped={skipped}, errors={errors}"
        )
        
        return {
            'snapshots_created': total_snapshots,
            'skipped': skipped,
            'errors': errors,
            'timestamp': timezone.now().isoformat()
        }
        
    except Exception as exc:
        logger.error(f"âŒ Price snapshot failed: {exc}")
        raise exc


@shared_task(bind=True)
def cleanup_old_price_history(self, days_to_keep: int = 90):
    """ì˜¤ë˜ëœ ê°€ê²© ì´ë ¥ ì •ë¦¬
    
    ì‹¤í–‰ ì£¼ê¸°: ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 3ì‹œ
    
    Args:
        days_to_keep: ë³´ê´€í•  ì¼ìˆ˜ (ê¸°ë³¸ 90ì¼)
    """
    try:
        from apps.products.models import PriceHistory
        from datetime import timedelta
        
        cutoff_date = timezone.now() - timedelta(days=days_to_keep)
        
        deleted_count, _ = PriceHistory.objects.filter(
            recorded_at__lt=cutoff_date
        ).delete()
        
        logger.info(
            f"ğŸ§¹ Cleaned up {deleted_count} old price history records "
            f"(older than {days_to_keep} days)"
        )
        
        return {
            'deleted': deleted_count,
            'cutoff_date': cutoff_date.isoformat()
        }
        
    except Exception as exc:
        logger.error(f"âŒ Price history cleanup failed: {exc}")
        raise exc


@shared_task(bind=True)
def cleanup_outdated_products(self, days_threshold: int = 30):
    """30ì¼ ì´ìƒ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì€ ìƒí’ˆ ì‚­ì œ
    
    ì‹¤í–‰ ì£¼ê¸°: ë§¤ì›” 1ì¼
    
    Args:
        days_threshold: ì‚­ì œ ê¸°ì¤€ ì¼ìˆ˜ (ê¸°ë³¸ 30ì¼)
    """
    try:
        from apps.products.models import GenericProduct
        from datetime import timedelta
        
        cutoff_date = timezone.now() - timedelta(days=days_threshold)
        
        deleted_count, _ = GenericProduct.objects.filter(
            updated_at__lt=cutoff_date,
            source='naver_shopping'
        ).delete()
        
        logger.info(
            f"ğŸ—‘ï¸  Deleted {deleted_count} outdated products "
            f"(not updated for {days_threshold} days)"
        )
        
        return {
            'deleted': deleted_count,
            'cutoff_date': cutoff_date.isoformat(),
            'days_threshold': days_threshold
        }
        
    except Exception as exc:
        logger.error(f"âŒ Product cleanup failed: {exc}")
        raise exc


@shared_task(bind=True, max_retries=2)
def generate_image_embedding(self, product_id: str, image_url: str):
    """ë‹¨ì¼ ìƒí’ˆì˜ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„±
    
    Args:
        product_id: ìƒí’ˆ ID
        image_url: ì´ë¯¸ì§€ URL
    
    Returns:
        dict: ì„ë² ë”© ìƒì„± ê²°ê³¼
    """
    try:
        from apps.recommendations.models import ImageEmbedding
        from apps.recommendations.services.image_embedding import ImageEmbeddingService
        
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        existing = ImageEmbedding.objects.filter(
            product_id=product_id,
            model_version='resnet50'
        ).exists()
        
        if existing:
            logger.debug(f"â­ï¸  Embedding already exists for {product_id}")
            return {'status': 'skipped', 'product_id': product_id}
        
        # ì„ë² ë”© ìƒì„±
        service = ImageEmbeddingService()
        embedding_vector = service.get_embedding_from_url(image_url)
        
        if embedding_vector is None:
            logger.warning(f"âš ï¸ Failed to generate embedding for {product_id}")
            return {'status': 'failed', 'product_id': product_id}
        
        # DB ì €ì¥
        ImageEmbedding.objects.create(
            product_id=product_id,
            image_url=image_url,
            embedding_vector=embedding_vector.tolist(),
            model_version='resnet50'
        )
        
        logger.info(f"âœ… Generated embedding for {product_id}")
        return {'status': 'created', 'product_id': product_id}
        
    except Exception as exc:
        logger.error(f"âŒ Embedding generation failed for {product_id}: {exc}")
        raise self.retry(exc=exc, countdown=60)  # 1ë¶„ í›„ ì¬ì‹œë„


@shared_task(bind=True)
def batch_generate_embeddings(self, limit: int = 100):
    """ì„ë² ë”©ì´ ì—†ëŠ” ìƒí’ˆë“¤ì˜ ì„ë² ë”© ì¼ê´„ ìƒì„±
    
    ì‹¤í–‰ ì£¼ê¸°: ë§¤ì¼ ìƒˆë²½ 2ì‹œ (Celery Beat)
    
    Args:
        limit: í•œ ë²ˆì— ì²˜ë¦¬í•  ìµœëŒ€ ìƒí’ˆ ìˆ˜
    
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ í†µê³„
    """
    try:
        from apps.products.models import GenericProduct
        from apps.recommendations.models import ImageEmbedding
        
        logger.info(f"ğŸ¨ Starting batch embedding generation (limit={limit})")
        
        # ì„ë² ë”© ì—†ëŠ” ìƒí’ˆ ID ì¡°íšŒ
        existing_product_ids = set(
            ImageEmbedding.objects.filter(model_version='resnet50')
            .values_list('product_id', flat=True)
        )
        
        # ì¬ê³  ìˆëŠ” ìƒí’ˆ ì¤‘ ì„ë² ë”© ì—†ëŠ” ê²ƒë“¤
        products_without_embedding = GenericProduct.objects.filter(
            in_stock=True
        ).exclude(
            id__in=existing_product_ids
        )[:limit]
        
        total_queued = 0
        total_skipped = 0
        
        for product in products_without_embedding:
            if not product.image_url:
                total_skipped += 1
                continue
            
            # ë¹„ë™ê¸°ë¡œ ì„ë² ë”© ìƒì„± íì‰
            generate_image_embedding.delay(
                product_id=str(product.id),
                image_url=product.image_url
            )
            total_queued += 1
        
        logger.info(
            f"âœ… Batch embedding generation queued: "
            f"queued={total_queued}, skipped={total_skipped}"
        )
        
        return {
            'queued': total_queued,
            'skipped': total_skipped,
            'timestamp': timezone.now().isoformat()
        }
        
    except Exception as exc:
        logger.error(f"âŒ Batch embedding generation failed: {exc}")
        raise exc


